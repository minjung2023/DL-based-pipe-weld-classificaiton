{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요한 라이브러리 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자로 전처리된 학습데이터의 경로, 학습횟수(EPOCH), 배치사이즈(BATCH_SIZE), 옵티마이저 종류(OPTIMIZER), \n",
    "# 학습률(LEARNING_RATE), 비용함수 종류(COST), 불러올 모델의 경로(MODEL_LOAD_PATH), 학습한 모델을 저장할 경로(MODEL_SAVE_PATH)를 \n",
    "# 인자로 받음\n",
    "\n",
    "def modeling(TRAIN_PATH, EPOCH, BATCH_SIZE,LEARNING_RATE, COST, MODEL_LOAD_PATH, MODEL_SAVE_PATH, OPTIMIZER):\n",
    "    \n",
    "    # 옵티마이저 선택지 (벡엔드에는 string 형식으로만 인자를 받을 수 있기 때문에)\n",
    "    optimizer_dic = {'RMSprop': optimizers.RMSprop, 'Adam' : optimizers.Adam}\n",
    "    \n",
    "    # 뭔가 잘못 입력되면 그냥 Adam을 optimizer로 사용할 수 있도록 \n",
    "    if ((OPTIMIZER!='Adam') or (OPTIMIZER!='RMSprops')):\n",
    "        OPTIMIZER = 'Adam'\n",
    "    \n",
    "    print(OPTIMIZER)\n",
    "    # 전이학습모델 불러오기 \n",
    "    model = load_model(MODEL_LOAD_PATH)\n",
    "    print(\"모델을 로드했습니다.\")\n",
    "    \n",
    "    # model compile (optimizer, learning rate, cost function 변경 가능)\n",
    "    model.compile(loss= COST,\n",
    "                  optimizer= optimizer_dic[OPTIMIZER](learning_rate = LEARNING_RATE),\n",
    "              metrics=[tf.keras.metrics.Precision(name='precision')\\\n",
    "                          ,tf.keras.metrics.Recall(name='recall')\\\n",
    "                          ,tf.keras.metrics.FalsePositives(name='false_positives')\\\n",
    "                          ,tf.keras.metrics.FalseNegatives(name='false_negatives')\\\n",
    "                          ,tfa.metrics.FBetaScore(num_classes=2,average=\"micro\",threshold=0.5)\n",
    "                          ,'acc'])\n",
    "    \n",
    "    # lr : 학습률 줄여나가기 \n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.9, patience=6, verbose=1)\n",
    "    \n",
    "    # es: 더 이상 validation loss가 줄어들지 않으면 멈추기\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    \n",
    "    # 모델에 넣을 데이터 불러오기 \n",
    "    accept_list = [TRAIN_PATH+'/ACCEPT/'+i for i in os.listdir(TRAIN_PATH+'/ACCEPT') if i.split('.')[-1]==\"npz\"]\n",
    "    reject_list = [TRAIN_PATH+'/REJECT/'+i for i in os.listdir(TRAIN_PATH+'/REJECT') if i.split('.')[-1]==\"npz\"]\n",
    "    \n",
    "    # accept 이미지들 받기 \n",
    "    accept_images = []\n",
    "    for idx,path in enumerate(accept_list):\n",
    "        accept_npz = np.load(path, allow_pickle=True)\n",
    "        accept_images.append(accept_npz['img'])\n",
    "    # 이중 리스트 풀기 \n",
    "    accept_images = np.concatenate(accept_images).tolist()\n",
    "    \n",
    "    # reject 이미지들 받기 \n",
    "    reject_images = []\n",
    "    for idx,path in enumerate(reject_list):\n",
    "        reject_npz = np.load(path, allow_pickle=True)\n",
    "        reject_images.append(reject_npz['img'])\n",
    "    # 이중 리스트 풀기\n",
    "    reject_images = np.concatenate(reject_images).tolist()\n",
    "    \n",
    "    # accept, reject 각각 라벨 생성\n",
    "    accept_label = [[1,0]]*len(accept_images)\n",
    "    reject_label = [[0,1]]*len(reject_images)\n",
    "    \n",
    "    # 각각 X랑 Y로 합치기 \n",
    "    X = accept_images + reject_images\n",
    "    Y = accept_label + reject_label \n",
    "    \n",
    "\n",
    "    # X와 Y를 train 데이터와 validation 데이터로 나누기 \n",
    "    tf.compat.v1.random.set_random_seed(777) \n",
    "    train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.2, random_state=777, shuffle=True, stratify=Y)\n",
    "    \n",
    "    # 학습시작\n",
    "    print(\"학습을 시작합니다.\")\n",
    "    history = model.fit(np.array(train_x).reshape(-1,400,400,1), np.array(train_y), \n",
    "                        epochs=EPOCH, verbose=0,callbacks=[es,lr],\n",
    "                        batch_size=BATCH_SIZE, validation_data = (np.array(val_x).reshape(-1,400,400,1),np.array(val_y)))\n",
    "    \n",
    "    # 학습된 모델을 지정 경로로 저장 \n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "    \n",
    "    # 벡엔드에서 출력값을 파싱하기 편하도록 함수 만들기\n",
    "    # ***.**** 으로 소숫점 앞은 세자리까지, 소숫점 뒤는 네자리까지 표기 하도록 \n",
    "    def make_output(number):\n",
    "        if(number>=1000):\n",
    "            number = '999.0000'\n",
    "        else:\n",
    "            if(number//10==0):\n",
    "                number = '00'+\"{:.4f}\".format(number)\n",
    "            elif(number//100==0):\n",
    "                number = '0'+\"{:.4f}\".format(number)\n",
    "            else:\n",
    "                number = \"{:.4f}\".format(number)\n",
    "        return number    \n",
    "    \n",
    "    # 모든 평가지표에 앞서 만든 함수를 적용하고 변수에 값을 할당하기 \n",
    "    for i in range(len(history.history['loss'])):\n",
    "        loss = make_output(history.history['loss'][i])\n",
    "        precision = make_output(history.history['precision'][i])\n",
    "        recall = make_output(history.history['recall'][i])\n",
    "        false_positives = make_output(history.history['false_positives'][i])\n",
    "        false_negatives = make_output(history.history['false_negatives'][i])\n",
    "        accuracy = make_output(history.history['acc'][i])\n",
    "        f1_score = make_output(history.history['fbeta_score'][i])\n",
    "        \n",
    "        # 벡엔드에서 파싱해서 값을 프론트로 넘겨줄 수 있도록 출력하기 \n",
    "        print(\"loss:\", loss, \"accuracy:\", accuracy, \"recall:\", recall, \"precision:\", precision, \"false_positives:\", false_positives, \n",
    "             \"false_negatives:\", false_negatives, \"f1_score:\", f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
