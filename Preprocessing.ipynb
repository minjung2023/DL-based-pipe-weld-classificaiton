{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import keras_ocr\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "import skimage\n",
    "from skimage import filters\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 함수 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 원본 path 리스트, array를 저장할 위치, 저장할 array의 이름을 인자로 받음\n",
    "def preprocessing(FILE_PATH,SAVE_PATH,SAVE_NAME):\n",
    "    # 글자 지우는 모델 선언 \n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    # 처리된 이미지들 받는 리스트 \n",
    "    processed = []\n",
    "    # 이미지 전처리 시작\n",
    "    FILE_PATH = [i for i in FILE_PATH if i[-3:]==\"tif\"]\n",
    "    \n",
    "    for f in FILE_PATH:\n",
    "        # 먼저 keras_ocr.tools.read로 이미지 내에 글자가 있는지 확인 \n",
    "        file_path = '/root/hyundairb/DRT_CUT/'+ f\n",
    "        img = keras_ocr.tools.read(f)\n",
    "        dst_img = cv2.imread(f,0)\n",
    "        prediction_groups = pipeline.recognize([img])\n",
    "        # 글씨가 있으면 글씨 영역의 좌표를 얻기\n",
    "        if(len(prediction_groups[0])!=0):\n",
    "            boundary = []\n",
    "            for i in range(len(prediction_groups[0])):\n",
    "                x = []\n",
    "                y = []\n",
    "                for j in range(len(prediction_groups[0][i][1])):\n",
    "                    x.append(prediction_groups[0][i][1][j][0])\n",
    "                    y.append(prediction_groups[0][i][1][j][1])\n",
    "                # 글씨 주변에 깔끔하지 못한 어두운 부분들도 함께 커버하기 위해 상하좌우로 11픽셀씩 더 커버하기 \n",
    "                x_min = int(np.where(math.floor(min(x)-11) > 0, math.floor(min(x)-11), 0))\n",
    "                x_max = math.ceil(max(x)+11)  \n",
    "                y_min = int(np.where(math.floor(min(y)-11) > 0, math.floor(min(y)-11), 0))\n",
    "                y_max = math.ceil(max(y)+11)\n",
    "                info_list = [x_min, x_max, y_min, y_max]\n",
    "                boundary.append(info_list)\n",
    "            \n",
    "            for i in range(len(boundary)):\n",
    "                # 가로 왼쪽으로 2픽셀 전, 세로는 글자 영역 높이의 절반 되는 지점의 색깔로 글자가 있는 곳을 가림\n",
    "                background = dst_img[boundary[i][2]+round(0.5*(y_max-y_min))][boundary[i][0]-2] # 픽셀\n",
    "                patch = np.full((boundary[i][3]-boundary[i][2],boundary[i][1]-boundary[i][0]),background) # 가리기\n",
    "                dst_img[boundary[i][2]:boundary[i][3], boundary[i][0]:boundary[i][1]] = patch\n",
    "            \n",
    "            # difference of gaussian으로 용접 부분 경계 추출하기 \n",
    "            Dog = filters.difference_of_gaussians(dst_img, 12,12*16)\n",
    "            # 찾은 경계를 90만큼 키워서 경계가 뚜렷해지도록 하기 \n",
    "            size = 90\n",
    "            minimum_trib = ndimage.minimum_filter(Dog, size)\n",
    "            # otsu 이진화로 검은 바탕에 용접부분 경계를 흰색으로 표시하기 \n",
    "            orig_sub_min = Dog - minimum_trib\n",
    "            thresh = threshold_otsu(orig_sub_min)\n",
    "            binary = orig_sub_min > thresh\n",
    "            bool_to_pix = np.where(binary==True,255,0)\n",
    "            bool_to_pix = np.array(bool_to_pix, dtype = \"uint8\")\n",
    "            # opening으로 용접부분 경계 외에 흰색으로 표시되는 노이즈를 제거 \n",
    "            rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(60,60))\n",
    "            opening = cv2.morphologyEx(bool_to_pix, cv2.MORPH_OPEN, rect_kernel)\n",
    "            \n",
    "            # 일부 경계 추출이 안되는 경우가 있어 try문으로 작성 \n",
    "            try:\n",
    "                # 흰색으로 표시된 용접 부분 경계의 가장 윗부분과 가장 아랫부분의 y좌표 추출\n",
    "                upper = np.max(np.where(opening==255)[0])+50\n",
    "                under = np.min(np.where(opening==255)[0])-50\n",
    "                # 원본 이미지에서 용접부분만 자르기 \n",
    "                cut_img = dst_img[under:upper,:]\n",
    "                # 이미지 내의 색상을 10가지 범위로 나누어서 10가지 색상으로 각각 채워 넣기 \n",
    "                section = pd.cut(np.concatenate(cut_img).tolist(), 10, labels = [0,28,56,84,112,140,168,196,224,252])\n",
    "                # 다시 이미지의 크기로 reshape 하기 \n",
    "                processed_img = np.array(section).reshape(np.array(cut_img).shape)\n",
    "                # 모델에 넣기 위해 이미지를 정규화하기 \n",
    "                normalized_img = processed_img.astype('float32') / 255.\n",
    "                # 모델에 넣기 위해 이미지를 (400,400) 크기로 만들기 \n",
    "                resized_img = cv2.resize(normalized_img,(400,400),cv2.INTER_AREA)\n",
    "                # 처리된 이미지 array를 processed 리스트에 append 하기 \n",
    "                processed.append(resized_img)\n",
    "                # 성공 메시지 출력\n",
    "                print(f, \": success\")\n",
    "            # 만약 어떠한 문제로 용접부분 경계 추출이 되지 않는 경우 해당 파일명을 던져주고 실패 메시지 출력\n",
    "            except StopIteration:\n",
    "                print(f, \": failed\")\n",
    "                break\n",
    "        # 이미지 상단에 아무런 글씨도 쓰여있지 않은 경우 글씨 제거 코드 제외 다른 코드는 동일함\n",
    "        else:\n",
    "            normal_img = cv2.imread(f, 0)\n",
    "            Dog = filters.difference_of_gaussians(normal_img, 12,12*16)\n",
    "            size = 90\n",
    "            minimum_trib = ndimage.minimum_filter(Dog, size)\n",
    "            orig_sub_min = Dog - minimum_trib\n",
    "            thresh = threshold_otsu(orig_sub_min)\n",
    "            binary = orig_sub_min > thresh\n",
    "            bool_to_pix = np.where(binary==True,255,0)\n",
    "            bool_to_pix = np.array(bool_to_pix, dtype = \"uint8\")\n",
    "            rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(60,60))\n",
    "            opening = cv2.morphologyEx(bool_to_pix, cv2.MORPH_OPEN, rect_kernel)\n",
    "            \n",
    "            try:\n",
    "                upper = np.max(np.where(opening==255)[0])+50\n",
    "                under = np.min(np.where(opening==255)[0])-50\n",
    "                cut_img = normal_img[under:upper,:]\n",
    "                section = pd.cut(np.concatenate(cut_img).tolist(), 10, labels = [0,28,56,84,112,140,168,196,224,252])\n",
    "                processed_img = np.array(section).reshape(np.array(cut_img).shape)\n",
    "                normalized_img = processed_img.astype('float32') / 255.\n",
    "                resized_img = cv2.resize(normalized_img,(400,400),cv2.INTER_AREA)\n",
    "                processed.append(resized_img)\n",
    "                print(f, \": success\")\n",
    "            except StopIteration:\n",
    "                print(f, \": failed\")\n",
    "                break\n",
    "            np.savez_compressed(SAVE_PATH+'/'+SAVE_NAME, img = processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
